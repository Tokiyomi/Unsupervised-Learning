{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e383c6e4",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "**IMPORTANT: DO NOT COPY OR SPLIT CELLS.** If you do, you'll mess the autograder. If need more cells to work or test things out, create a new cell. You may add as many new cells as you need.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and group below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db3d2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "COURSE = \"Unsupervised Learning 2021\"\n",
    "GROUP = \"D8A\"\n",
    "NAME = \"Tokiyomi\" # Match your GitHub Classroom ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2270d923",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9844000a",
   "metadata": {},
   "source": [
    "# **Warning**:\n",
    "\n",
    "Make sure your whole notebooks executes in a reasonable amount of time (< 10 min), less it will not be graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2cb4178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from numba import jit, njit\n",
    "import numba\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebdb6a",
   "metadata": {},
   "source": [
    "# Exercise 1 (2 pt)\n",
    "\n",
    "Compute the simple matching coefficient, cosine similarity, and the Jaccard coefficient, between the two sets {A,B,C} and {A,C,D,E}.\n",
    "\n",
    "To do so, modify the functions for each similarity to work with sets instead of vectors.\n",
    "\n",
    "Compare your functions output with a manual calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3962e949",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9323c6d30ab3760c87e5e71596346b6b",
     "grade": false,
     "grade_id": "ex1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def smc(A, B):\n",
    "    # Intersection \n",
    "    return len(A&B) \n",
    "    \n",
    "def cosine_s(A, B):\n",
    "    # Intersection / sqrt(|A| x |B|)\n",
    "    return len(A&B) / np.sqrt(len(A)*len(B))\n",
    "\n",
    "def jaccard(A, B):\n",
    "    # Intersection / Union\n",
    "    return len(A&B)/len(A|B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d1e358",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2af75eaa9b277080e520cc7ffa8019d0",
     "grade": true,
     "grade_id": "ex1-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Simple matching coefficient: 2\nCosine similarity: 0.5773502691896258\nJaccard index: 0.4\n"
     ]
    }
   ],
   "source": [
    "s1 = {'A', 'B', 'C'}\n",
    "s2 = {'A', 'C', 'D', 'E'}\n",
    "\n",
    "print(f'Simple matching coefficient: {smc(s1, s2)}')\n",
    "print(f'Cosine similarity: {cosine_s(s1, s2)}')\n",
    "print(f'Jaccard index: {jaccard(s1, s2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1900d1b9",
   "metadata": {},
   "source": [
    "# Exercise 2 (3 pt)\n",
    "\n",
    "## The data set\n",
    "\n",
    "Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "\n",
    "Prediction task is to determine whether a person makes over 50K a year.\n",
    "\n",
    "\n",
    "Listing of attributes:\n",
    "\n",
    "- class: >50K, <=50K.\n",
    "\n",
    "- age: continuous.\n",
    "- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "- fnlwgt: continuous.\n",
    "- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "- education-num: continuous.\n",
    "- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "- race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "- sex: Female, Male.\n",
    "- capital-gain: continuous.\n",
    "- capital-loss: continuous.\n",
    "- hours-per-week: continuous.\n",
    "- native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d879c544",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(30162, 15)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country      y  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Load the complete data set\n",
    "with open('adult.names', 'r') as f:\n",
    "    lines = [l.strip() for l in f.readlines()][-14:]\n",
    "cols = [l.split(':')[0] for l in lines] + ['y']\n",
    "cols\n",
    "df = pd.read_csv('adult.data', names=cols, na_values='?', skipinitialspace=True)\n",
    "df = df.dropna()\n",
    "# added reset index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe2ec1",
   "metadata": {},
   "source": [
    "## Part 1 (2 pt)\n",
    "\n",
    "Using the _Adults Data Set_ from the _UCI Machine Learning Repository_ (provided), create a data set containing only the categorical attributes. Compute the nearest neighbor for each data point using \n",
    "- (a) the SMC (1 pt)\n",
    "- (b) inverse ocurrence frequency measure (1 pt)\n",
    "\n",
    "Compute the number of cases where there is a match on the class label, store them into `match_smc` and `match_iof`.\n",
    "When there are ties among NN, the 1st NN match is undefined and depends on the ordering of the data, but the distributions of distances is well defined. Use Counter class to find the distribution of distances and store the dictionaries in `dist_smc` and `dist_iof`.\n",
    "\n",
    "Hints: \n",
    "- Do not try to compute the full distance matrix, you may run into memory issues.\n",
    "- The data set is large, even at 10%, so pure Python loops will be slow, try using numba for just in time compilation. Sklearn with cythonized custom metrics may work, but I've had issues since sklearn tends to report a point as its self NN, not necessarly the first one, if many neighbors with the same distance exist.\n",
    "- Test your code with a small sample of the data to avoid waiting much time for completion during testing.\n",
    "- Note: This hints were valid for the kdd cup data set, consisiting of ~5million records, memory issues may no longer apply to the significantly smaller bank dataset\n",
    "\n",
    "Extra points if able to find a way to perform the excercise for the full KDD Cup data set in a reasonable time, using 100k rows, for SMC, my personal laptop takes ~ 5 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(df['y'])['<=50K']\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501ecff",
   "metadata": {},
   "source": [
    "### Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae74be23",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb49d9fbd66da9ecacaff2c485dffd5b",
     "grade": false,
     "grade_id": "ex2-p1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Categorical dataset\n",
    "cat_df = df[['workclass','education','marital-status','occupation','relationship','race','sex','native-country']]\n",
    "\n",
    "# usar sample\n",
    "sample = cat_df\n",
    "sample = sample.apply(lambda x: pd.factorize(x)[0])\n",
    "sample = sample.to_numpy()\n",
    "\n",
    "\n",
    "# SMC\n",
    "# compute NN\n",
    "@jit(nopython=True)\n",
    "def compute_smc(sample, target):\n",
    "    smc_distances = np.zeros((len(sample)))\n",
    "    \n",
    "    matches_count = 0\n",
    "\n",
    "    for i in range(len(sample)):\n",
    "        smc_dist = -1\n",
    "        smc_idx = -1\n",
    "        for j in range(len(sample)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            dist = ((sample[i] == sample[j]).sum()) / (len(sample[i]))\n",
    "            if dist > smc_dist:\n",
    "                smc_dist = dist\n",
    "                smc_idx = j\n",
    "        if target[i] == target[smc_idx]:\n",
    "            matches_count += 1\n",
    "\n",
    "        smc_distances[i] = smc_dist\n",
    "        \n",
    "\n",
    "    return (1 - smc_distances, matches_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Elapsed (with compilation) = 153.80569458007812\n"
     ]
    }
   ],
   "source": [
    "# COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME\n",
    "start = time.time()\n",
    "dist_smc, match_smc = compute_smc(sample, y)\n",
    "end = time.time()\n",
    "print(\"Elapsed (with compilation) = %s\" % (end - start))\n",
    "dist_smc = Counter(dist_smc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23244\nCounter({0.0: 25005, 0.125: 4612, 0.25: 521, 0.375: 24})\n"
     ]
    }
   ],
   "source": [
    "print(match_smc)\n",
    "print(dist_smc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc0f351",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "419e621c8c9737f5fa00b2af15e02d14",
     "grade": true,
     "grade_id": "ex2-p1a-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Matches using SMC or equivalent: 23244, expected arround: 20k-25k\nThe distribution of distances is: Counter({0.0: 25005, 0.125: 4612, 0.25: 521, 0.375: 24})\nExpected:\n{0.0: 25005,\n 0.125: 4612,\n 0.25: 521,\n 0.375: 24}\n"
     ]
    }
   ],
   "source": [
    "print(f'Matches using SMC or equivalent: {match_smc}, expected arround: 20k-25k')\n",
    "print(f'The distribution of distances is: {dist_smc}')\n",
    "print('Expected:\\n{0.0: 25005,\\n 0.125: 4612,\\n 0.25: 521,\\n 0.375: 24}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9489028",
   "metadata": {},
   "source": [
    "### Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for feature in range(len(sample.T)):\n",
    "    result_feature = []\n",
    "    unique_values = np.unique(sample.T[feature])\n",
    "    for unique in unique_values:\n",
    "        inv_freq =  (len(sample.T[0]) / (sample.T[feature]==unique).sum())**2\n",
    "        result_feature.append(inv_freq)\n",
    "    result.append(result_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 5, 6, 7], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "indices_true, = np.where(sample[0] == sample[1])\n",
    "indices_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist(dic,i,j):\n",
    "    indices_true, = np.where(sample[i] == sample[j])\n",
    "    suma = 0\n",
    "    for idx in indices_true:\n",
    "        inv_freq = dic[idx][sample[i][idx]]\n",
    "        suma += inv_freq\n",
    "    return suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "40.50344794987936"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "compute_dist(result,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "818bfd27",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7cfafb43fd48e25c9bfbe76868afbeb2",
     "grade": false,
     "grade_id": "ex2-p1b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def compute_iof(sample, target):\n",
    "    # create dict of inv frequencies\n",
    "    result = []\n",
    "    for feature in range(len(sample.T)):\n",
    "        result_feature = []\n",
    "        unique_values = np.unique(sample.T[feature])\n",
    "        for unique in unique_values:\n",
    "            inv_freq =  (len(sample.T[0]) / (sample.T[feature]==unique).sum())**2\n",
    "            result_feature.append(inv_freq)\n",
    "        result.append(result_feature)\n",
    "    # compute NN\n",
    "    iof_distances = np.zeros((len(sample)))\n",
    "    matches_count = 0\n",
    "    for i in range(len(sample)):\n",
    "        iof_dist = -1\n",
    "        iof_idx = -1\n",
    "        for j in range(len(sample)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            # compute inv freq\n",
    "            indices_true, = np.where(sample[i] == sample[j])\n",
    "            suma = 0\n",
    "            for idx in indices_true:\n",
    "                inv_freq = result[idx][sample[i][idx]]\n",
    "                suma += inv_freq\n",
    "            dist = suma\n",
    "            if dist > iof_dist:\n",
    "                iof_dist = dist\n",
    "                iof_idx = j\n",
    "                \n",
    "        if target[i] == target[iof_idx]:\n",
    "            matches_count += 1\n",
    "\n",
    "        iof_distances[i] = iof_dist\n",
    "        \n",
    "    return (iof_distances, matches_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Elapsed (with compilation) = 342.3478891849518\n"
     ]
    }
   ],
   "source": [
    "# COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME\n",
    "start = time.time()\n",
    "dist_iof, match_iof = compute_iof(sample, y)\n",
    "end = time.time()\n",
    "print(\"Elapsed (with compilation) = %s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_iof = Counter(dist_iof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49984ec8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b5c180d9a405f32a38ae5b49ba8eb9b",
     "grade": true,
     "grade_id": "ex2-p1b-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Matches using IOF or equivalent: 23219, expected arround: 20k-25k\nThe top 5 distances are: [(82.44464251281097, 803), (109.878174587436, 448), (261.80004755602187, 368), (93.44879430104447, 345), (394.5707372393568, 332)]\nExpected:\n(82.44464251281099, 803),\n (109.87817458743599, 448),\n (261.80004755602187, 368),\n (93.44879430104449, 345),\n (394.57073723935673, 332)\n"
     ]
    }
   ],
   "source": [
    "print(f'Matches using IOF or equivalent: {match_iof}, expected arround: 20k-25k')\n",
    "print(f'The top 5 distances are: {dist_iof.most_common(5)}')\n",
    "print('Expected:\\n(82.44464251281099, 803),\\n (109.87817458743599, 448),\\n (261.80004755602187, 368),\\n (93.44879430104449, 345),\\n (394.57073723935673, 332)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcc306",
   "metadata": {},
   "source": [
    "## Part 2 (1 pt)\n",
    "\n",
    "Now, create a data set using only the quantitative attributes of the data set. Use the $L_p$ norm for values $p=1,2,\\infty$ to find the nearest neighbors and count the matches. Store the matches into `match_l1`, `match_l2`, and `match_linf` respectively and distributions into `dist_l1`, `dist_l2`, and `dist_linf`. Use sklearn for this part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeecf87c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6983fa858de0a124c3e4aa3409a1caef",
     "grade": false,
     "grade_id": "ex2-p2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "num_df = df[['age','fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']]\n",
    "num_df = num_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches_and_dist(df, target, p):\n",
    "    nbrs = NearestNeighbors(n_neighbors=2, p=p).fit(df)\n",
    "    distances, indices = nbrs.kneighbors(df)\n",
    "    distribution = Counter(distances[:,1])\n",
    "    matches_count = (target == target[indices[:,1]]).sum()\n",
    "    return matches_count, distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_l1, dist_l1 = get_matches_and_dist(num_df,y, p=1)\n",
    "match_l2, dist_l2 = get_matches_and_dist(num_df,y, p=2)\n",
    "match_linf, dist_linf = get_matches_and_dist(num_df,y, p=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39f3d156",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab1c37f80d8cd0cbc756dab559a30786",
     "grade": true,
     "grade_id": "ex2-p2-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Matches are: Manhattan: 22091, Euclidean: 21969, Chebyshev: 21854\nExpected (arround): Manhattan: 22097, Euclidean: 21984, Chebyshev: 21826\nDistributions most commont:\n Manhattan: [(5.0, 884)],\n Euclidean: [(1.0, 837)],\n Chebyshev: [(10.0, 2507)]\nExpected:\n Manhattan: [(5.0, 884)],\n Euclidean: [(1.0, 837)],\n Chebyshev: [(10.0, 2507)]\n"
     ]
    }
   ],
   "source": [
    "print(f'Matches are: Manhattan: {match_l1}, Euclidean: {match_l2}, Chebyshev: {match_linf}')\n",
    "print('Expected (arround): Manhattan: 22097, Euclidean: 21984, Chebyshev: 21826')\n",
    "print(f'Distributions most commont:\\n Manhattan: {dist_l1.most_common(1)},\\n Euclidean: {dist_l2.most_common(1)},\\n Chebyshev: {dist_linf.most_common(1)}')\n",
    "print('Expected:\\n Manhattan: [(5.0, 884)],\\n Euclidean: [(1.0, 837)],\\n Chebyshev: [(10.0, 2507)]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d10e43",
   "metadata": {},
   "source": [
    "## Part 3 (2 pts)\n",
    "\n",
    "Repeat for the complete data set. Implement and use the mixed-attribute function, un-normalized, and transform the numerical distances to a similaroty using $s = 1/(1+d)$. Use euclidean distance for numerical attributes. Save matches and distribution into `match_mix` and `dist_mix`.\n",
    "\n",
    "\n",
    "\n",
    "Tip: Continue the numba approach to build a custom similarity metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d66caa6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ba67d737c3b0f0ec9ffd493f307727f",
     "grade": false,
     "grade_id": "ex2-p3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def compute_mixed(sample_c, sample_r, target):\n",
    "    sim_measures = np.zeros((len(sample_c)))\n",
    "    #sim_indices = np.zeros((len(sample_c)))\n",
    "    matches_count = 0\n",
    "    # set lambda ad the fraction of real features, should be 6/14\n",
    "    l = len(sample_r[0])/(len(sample_c[0])+len(sample_r[0]))\n",
    "\n",
    "    for i in range(len(sample_c)):\n",
    "        max_sim = -1\n",
    "        sim_idx = -1\n",
    "        for j in range(len(sample_c)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            sim_c = (((sample_c[i] == sample_c[j]).sum()) / (len(sample_c[i])))\n",
    "\n",
    "            dist_r = 0\n",
    "            for z in range(len(sample_r[0])):\n",
    "                dist_r += (sample_r[i][z]-sample_r[j][z])**2\n",
    "            dist_r = np.sqrt(dist_r)\n",
    "            sim_r = 1/(1+dist_r)\n",
    "\n",
    "            sim_rc = l*sim_r + (1-l)*sim_c\n",
    "            if sim_rc > max_sim:\n",
    "                max_sim = sim_rc\n",
    "                sim_idx = j\n",
    "            \n",
    "        if target[i]==target[sim_idx]:\n",
    "            matches_count += 1\n",
    "\n",
    "        sim_measures[i] = max_sim\n",
    "        #sim_indices[i] = sim_idx\n",
    "\n",
    "    return (sim_measures, matches_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Elapsed (with compilation) = 161.8349461555481\n"
     ]
    }
   ],
   "source": [
    "# COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME\n",
    "start = time.time()\n",
    "a,b=compute_mixed(sample[:], num_df[:], y[:])\n",
    "end = time.time()\n",
    "print(\"Elapsed (with compilation) = %s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0.6428571428571428, 314),\n",
       " (0.7142857142857143, 170),\n",
       " (0.9285714285714286, 131),\n",
       " (0.6060915267313265, 104)]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "dist_mix = Counter(a)\n",
    "dist_mix.most_common(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "23311"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "match_mix = b\n",
    "match_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "754aa44d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70a0b60d2f10088a2129742c8195d7db",
     "grade": true,
     "grade_id": "ex2-part3-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Matches: 23311\nExpected (arround): 22520\nDistribution 4 most common:\n [(0.6428571428571428, 314), (0.7142857142857143, 170), (0.9285714285714286, 131), (0.6060915267313265, 104)]\nExpected:\n [(0.6904761904761905, 837),\n (0.5133882356845012, 439),\n (0.6190476190476191, 426),\n (1.0, 404)]\n"
     ]
    }
   ],
   "source": [
    "print(f'Matches: {match_mix}')\n",
    "print('Expected (arround): 22520')\n",
    "print(f'Distribution 4 most common:\\n {dist_mix.most_common(4)}')\n",
    "print('Expected:\\n [(0.6904761904761905, 837),\\n (0.5133882356845012, 439),\\n (0.6190476190476191, 426),\\n (1.0, 404)]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aba6ae",
   "metadata": {},
   "source": [
    "# Exercise 3 (4 pts)\n",
    "\n",
    "## Part 1 (1 pt)\n",
    "\n",
    "Implement the edit or Levenshtein distance. Provided start code is a sugestion, you may implement from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bfcb36b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8e65b79f3ee11d6805d123b257912f0",
     "grade": false,
     "grade_id": "ex3-p1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def leveshtein_d(src, dest):\n",
    "    n = len(src)\n",
    "    m = len(dest)\n",
    "\n",
    "    if type(src) is str:\n",
    "        src = list(src)\n",
    "    if type(dest) is str:\n",
    "        dest = list(dest)\n",
    "        \n",
    "    \n",
    "    # for all i and j, d[i,j] will hold the Levenshtein distance\n",
    "    # between the first i characters of src\n",
    "    # and the first j characters of dest\n",
    "    # note that d has (n+1)*(m+1) values to account for the\n",
    "    # empty string\n",
    "\n",
    "    D = np.zeros((n+1,m+1), dtype=int)\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        D[i,0] = i\n",
    "    for j in range(1,m+1):\n",
    "        D[0,j] = j\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        for j in range(1,m+1):\n",
    "            if src[i-1] == dest[j-1]:\n",
    "                D[i][j] = min(D[i-1][j] + 1, D[i][j-1] + 1, D[i-1][j-1])\n",
    "            else:\n",
    "                D[i][j] = min(D[i-1][j] + 1, D[i][j-1] + 1, D[i-1][j-1] +1)\n",
    "    print(D)\n",
    "\n",
    "    return D[n,m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63770055",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca9111fbed640c08c7a266ac066cf118",
     "grade": true,
     "grade_id": "cell-20b0d3c70d948876",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 1 2 3 4 5 6]\n [1 1 2 3 4 5 6]\n [2 2 1 2 3 4 5]\n [3 3 2 1 2 3 4]\n [4 4 3 2 1 2 3]\n [5 5 4 3 2 2 3]\n [6 6 5 4 3 3 2]\n [7 7 6 5 4 4 3]]\nLeveshtein distance between \"sitting\" and \"kitten\" should be 3, calculated distance: 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Leveshtein distance between \"sitting\" and \"kitten\" should be 3, calculated distance: {leveshtein_d(\"sitting\",\"kitten\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f762fa5",
   "metadata": {},
   "source": [
    "## Part 2 (1 pt)\n",
    "\n",
    "Impement the LCSS distance. The function must return the distance and the set of all common subsequences as tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e6f161f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1536e0b62081fbb5303cd6ae8690604",
     "grade": false,
     "grade_id": "ex3-p2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def lccs_d(x, y):\n",
    "    n = len(x)\n",
    "    m = len(y)\n",
    "\n",
    "    if type(x) is str:\n",
    "        x = list(x)\n",
    "    if type(y) is str:\n",
    "        y = list(y)\n",
    "\n",
    "    # The matrix will hold initial values D[0,j], D[i,0]\n",
    "    # which mean nothing (distance to the empty vector)\n",
    "    # so set them to 0\n",
    "    D = np.zeros((n+1,m+1), dtype=int)\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        D[i,0] = 0\n",
    "\n",
    "    for j in range(1,m+1):\n",
    "        D[0,j] = 0\n",
    "\n",
    "    for i in range(1,n + 1):\n",
    "        for j in range(1,m + 1):\n",
    "            if x[i-1] == y[j-1]:\n",
    "                D[i][j] = D[i-1][j-1]+1\n",
    "            else:\n",
    "                D[i][j] = max(D[i-1][j], D[i][j-1])\n",
    "    print(D)\n",
    "\n",
    "    # Apply traceback to find set LCCS\n",
    "    def backtrack(n, m):\n",
    "        # construct a set to store possible LCS\n",
    "        s = set()\n",
    "    \n",
    "        # If we reaches end of either string, return a empty set\n",
    "        if n == 0 or m == 0:\n",
    "            s.add(\"\")\n",
    "            return s\n",
    "    \n",
    "        # If the last characters of X and Y are same\n",
    "        if x[n - 1] == y[m - 1]:\n",
    "            # recurssion\n",
    "            tmp = backtrack(n - 1, m - 1)\n",
    "    \n",
    "            # append current character to all possible LCS of substring X[0..n-2] and Y[0..m-2].\n",
    "            for string in tmp:\n",
    "                s.add(string + x[n - 1])\n",
    "    \n",
    "        # If the last characters of X and Y are not same\n",
    "        else:\n",
    "    \n",
    "            # If LCS can be constructed from top side of the matrix, recurse for X[0..n-2] and Y[0..m-1]\n",
    "            if D[n - 1][m] >= D[n][m - 1]:\n",
    "                s = backtrack(n - 1, m)\n",
    "    \n",
    "            # If LCS can be constructed from left side of the matrix, recurse for X[0..n-1] and Y[0..m-2]\n",
    "            if D[n][m - 1] >= D[n - 1][m]:\n",
    "                tmp = backtrack(n, m - 1)\n",
    "    \n",
    "                # merge two sets if D[n-1][m] == L[n][m-1]\n",
    "                for i in tmp:\n",
    "                    s.add(i)\n",
    "        return s\n",
    "\n",
    "    lcs_set = backtrack(n, m)\n",
    "\n",
    "    lcs_set = set(map(tuple, lcs_set))\n",
    "\n",
    "    return D[n, m], lcs_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 0 0 0]\n [0 0 1 1 1 1]\n [0 1 1 1 2 2]\n [0 1 1 2 2 2]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2, {('A', 'C'), ('G', 'A'), ('G', 'C')})"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "lccs_d('GAC','AGCAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cbdc028",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c880c6e56ae4f92a27a8f54051be73b",
     "grade": true,
     "grade_id": "ex3-p2-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 0 0 0]\n [0 0 1 1 1 1]\n [0 1 1 1 2 2]\n [0 1 1 2 2 2]]\nThe LCSS has length 2, expected value is 2.\nThe set of LCCSs is {('A', 'C'), ('G', 'C'), ('G', 'A')}\nThe expected set is: {('G', 'C'), ('A', 'C'), ('G', 'A')}\n"
     ]
    }
   ],
   "source": [
    "d = lccs_d('GAC','AGCAT')\n",
    "print(f'The LCSS has length {d[0]}, expected value is 2.')\n",
    "print(f'The set of LCCSs is {d[1]}')\n",
    "print(\"The expected set is: {('G', 'C'), ('A', 'C'), ('G', 'A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af02cac",
   "metadata": {},
   "source": [
    "## Part 3 (1 pt)\n",
    "\n",
    "Implement the DTW distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94da9ad4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf21ea01620c59e43f0704611a3d3079",
     "grade": false,
     "grade_id": "ex3-p3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def dtw_d(x, y):\n",
    "\n",
    "    n = len(x)\n",
    "    m = len(y)\n",
    "\n",
    "    D = np.zeros((n+1, m+1), dtype=int)\n",
    "\n",
    "    for i in range(1,n+1):\n",
    "        D[i,0] = i\n",
    "    for j in range(1,m+1):\n",
    "        D[0,j] = j\n",
    "\n",
    "    #D[0, 0] = 0 # starting position\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            cost = abs(x[i-1] - y[j-1])\n",
    "            last_min = min(D[i-1][j], D[i][j-1], D[i-1][j-1])\n",
    "            D[i, j] = cost + last_min\n",
    "    print(D)\n",
    "    return D[n, m]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e71f9788",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e448df1de061cae5d38a06b600c5b94",
     "grade": true,
     "grade_id": "ex3-p3-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 1 2 3 4]\n [1 0 1 3 7]\n [2 1 0 1 4]\n [3 3 1 0 2]]\nThe DTW distance for the example is 2, expected value is 2.\n"
     ]
    }
   ],
   "source": [
    "d = dtw_d([1,2,3], [1,2,3,5])\n",
    "print(f'The DTW distance for the example is {d}, expected value is 2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a133061",
   "metadata": {},
   "source": [
    "Check your implementations by computing by hand each of the lcss and leveshtein distances for the pairs **(1 pt)**, and compare them to the programmed solutions (no need to provide calulations):\n",
    "- ababcabc, babcbc\n",
    "- cbacbacba, acbacbacb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54ffb2d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26663c77bdb277098bd560b7c4d828fd",
     "grade": true,
     "grade_id": "cell-73cd0b85cf4ff162",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 1 2 3 4 5 6]\n [1 1 1 2 3 4 5]\n [2 1 2 1 2 3 4]\n [3 2 1 2 2 3 4]\n [4 3 2 1 2 2 3]\n [5 4 3 2 1 2 2]\n [6 5 4 3 2 2 3]\n [7 6 5 4 3 2 3]\n [8 7 6 5 4 3 2]]\n2\n[[0 1 2 3 4 5 6 7 8 9]\n [1 1 1 2 3 4 5 6 7 8]\n [2 2 2 1 2 3 4 5 6 7]\n [3 2 3 2 1 2 3 4 5 6]\n [4 3 2 3 2 1 2 3 4 5]\n [5 4 3 2 3 2 1 2 3 4]\n [6 5 4 3 2 3 2 1 2 3]\n [7 6 5 4 3 2 3 2 1 2]\n [8 7 6 5 4 3 2 3 2 1]\n [9 8 7 6 5 4 3 2 3 2]]\n2\n[[0 0 0 0 0 0 0]\n [0 0 1 1 1 1 1]\n [0 1 1 2 2 2 2]\n [0 1 2 2 2 2 2]\n [0 1 2 3 3 3 3]\n [0 1 2 3 4 4 4]\n [0 1 2 3 4 4 4]\n [0 1 2 3 4 5 5]\n [0 1 2 3 4 5 6]]\n(6, {('b', 'a', 'b', 'c', 'b', 'c')})\n[[0 0 0 0 0 0 0 0 0 0]\n [0 0 1 1 1 1 1 1 1 1]\n [0 0 1 2 2 2 2 2 2 2]\n [0 1 1 2 3 3 3 3 3 3]\n [0 1 2 2 3 4 4 4 4 4]\n [0 1 2 3 3 4 5 5 5 5]\n [0 1 2 3 4 4 5 6 6 6]\n [0 1 2 3 4 5 5 6 7 7]\n [0 1 2 3 4 5 6 6 7 8]\n [0 1 2 3 4 5 6 7 7 8]]\n(8, {('c', 'b', 'a', 'c', 'b', 'a', 'c', 'b')})\n"
     ]
    }
   ],
   "source": [
    "print(leveshtein_d('ababcabc', 'babcbc'))\n",
    "print(leveshtein_d('cbacbacba', 'acbacbacb'))\n",
    "print(lccs_d('ababcabc', 'babcbc'))\n",
    "print(lccs_d('cbacbacba', 'acbacbacb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d000b820",
   "metadata": {},
   "source": [
    "# Exercise 4 (1 pt)\n",
    "\n",
    "Compute the cosine similarity between the two sentences, store into `cos`:\n",
    "- The sly fox jumped over the lazy dog.\n",
    "- The dog jumped at the intruder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe0eacd5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77c0950f48c31968d3cd72934b2412ff",
     "grade": false,
     "grade_id": "ex4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'lazy', 'intruder', 'the', 'dog', 'at', 'over', 'jumped', 'fox', 'sly'}\n[1 0 2 1 0 1 1 1 1]\n[0 1 2 1 1 0 1 0 0]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6708203932499369"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "def vectorize(text, word_set):\n",
    "    vector = []\n",
    "    for i in word_set:\n",
    "        count = 0    \n",
    "        for item in text:\n",
    "            if i == item:\n",
    "                count += 1\n",
    "        vector.append(count)\n",
    "    return np.array(vector)\n",
    "\n",
    "def cos_sim(text1,text2):\n",
    "    # compute the union of the text\n",
    "    A, B = text1.lower().split(' '), text2.lower().split(' ') \n",
    "    word_set = set(A) | set(B)\n",
    "    print(word_set)\n",
    "    #vectorize\n",
    "    a = vectorize(A, word_set)\n",
    "    print(a)\n",
    "    b = vectorize(B, word_set)\n",
    "    print(b)\n",
    "    # compute numerical cos sim\n",
    "    return (a@b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "cos = cos_sim('The sly fox jumped over the lazy dog','The dog jumped at the intruder')\n",
    "cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd664ee1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19f6a63234c010cb358112f4b095ca72",
     "grade": true,
     "grade_id": "ex4-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The cosine similarity is 0.6708203932499369, expected: 0.6708203932499369\n"
     ]
    }
   ],
   "source": [
    "print(f'The cosine similarity is {cos}, expected: {6/np.sqrt(80)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d58f8a",
   "metadata": {},
   "source": [
    "# Exercise 5 (ungraded)\n",
    "\n",
    "## Part 1\n",
    "\n",
    "Assume $Edit(\\bar{X},\\bar{Y})$ represents the cost of transforming string $\\bar{X}$ to $\\bar{Y}$. Show that $Edit(\\bar{X},\\bar{Y})$ and $Edit(\\bar{Y},\\bar{X})$ are the same, as long as the insertion and deletion costs are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f351a2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04c64bb8a27b7f83e481952c0b5608f2",
     "grade": true,
     "grade_id": "cell-7adaeda461f3bb42",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Using the leveshtein distance:  leveshtein_d(X,Y)=D and leveshtein_d(Y,X)=D_Transpose \n",
    "\n",
    "Therefore, D(len(X),len(Y)) = D_Transpose(len(Y),len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 1 2 3 4 5 6]\n [1 1 1 2 3 4 5]\n [2 1 2 1 2 3 4]\n [3 2 1 2 2 3 4]\n [4 3 2 1 2 2 3]\n [5 4 3 2 1 2 2]\n [6 5 4 3 2 2 3]\n [7 6 5 4 3 2 3]\n [8 7 6 5 4 3 2]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "leveshtein_d('ababcabc', 'babcbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 1 2 3 4 5 6 7 8]\n [1 1 1 2 3 4 5 6 7]\n [2 1 2 1 2 3 4 5 6]\n [3 2 1 2 1 2 3 4 5]\n [4 3 2 2 2 1 2 3 4]\n [5 4 3 3 2 2 2 2 3]\n [6 5 4 4 3 2 3 3 2]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "leveshtein_d('babcbc','ababcabc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2606701",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Show that $Edit(\\vec{x}_i,\\vec{y}_j)$, $LCSS(\\vec{x}_i,\\vec{y}_j)$, and $DTW(\\vec{x}_i,\\vec{y}_j)$ are all monotonic functions in $i$ and $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c148f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "459eeb7825851bf9cd9c24d5e4ff92d4",
     "grade": true,
     "grade_id": "cell-ab7232ba9e71d8a2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd1ade",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "Suppose that insertion and deletion costs are 1, and replacement costs are 2 units for the edit distance. Show that the optimal edit distance between two strings can be computed only with insertion and deletion operations. Under the aftermentioned cost assumptions, show that the optimal edit distance can be expressed as a function of the optimal LCSS distance and the length of the two strings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fccb79",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c5c9187b1c59d17cbc409b112a25d6b",
     "grade": true,
     "grade_id": "cell-6780559de3a6f6f4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd076e3749c4d8f143b85e17554ce3ae58a0fcf4212a15be7e0134aaba6048266e3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}